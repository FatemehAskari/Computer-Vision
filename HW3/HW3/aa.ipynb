{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"images/Q4/2.jpg\"\n",
    "image = cv2.imread(\"images/Q4/2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_and_threshold(gray):\n",
    "    gray = cv2.GaussianBlur(gray,(3,3),2)\n",
    "    threshold = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "    threshold = cv2.fastNlMeansDenoising(threshold, 11, 31, 9)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def biggest_contour(contours,min_area):\n",
    "    biggest = None\n",
    "    max_area = 0\n",
    "    biggest_n=0\n",
    "    approx_contour=None\n",
    "    for n,i in enumerate(contours):\n",
    "            area = cv2.contourArea(i)\n",
    "         \n",
    "            \n",
    "            if area > min_area/10:\n",
    "                    peri = cv2.arcLength(i,True)\n",
    "                    approx = cv2.approxPolyDP(i,0.02*peri,True)\n",
    "                    if area > max_area and len(approx)==4:\n",
    "                            biggest = approx\n",
    "                            max_area = area\n",
    "                            biggest_n=n\n",
    "                            approx_contour=approx\n",
    "                            \n",
    "                                                   \n",
    "    return biggest_n,approx_contour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    pts=pts.reshape(4,2)\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "   \n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **1. Convert the image to grayscale**\n",
    "\n",
    "# **2. Remove noise and smoothen out the image by applying blurring and thresholding techniques**\n",
    "\n",
    "# **3. Use Canny Edge Detection to find the edges**\n",
    "\n",
    "# **4. Find the biggest contour and crop it out**\n",
    "\n",
    "\n",
    "def transformation(image):\n",
    "  image=image.copy()  \n",
    "  height, width, channels = image.shape\n",
    "  gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "  image_size=gray.size\n",
    "  \n",
    "  threshold=blur_and_threshold(gray)\n",
    "  # We need two threshold values, minVal and maxVal. Any edges with intensity gradient more than maxVal \n",
    "  # are sure to be edges and those below minVal are sure to be non-edges, so discarded. \n",
    "  #  Those who lie between these two thresholds are classified edges or non-edges based on their connectivity.\n",
    "  # If they are connected to \"sure-edge\" pixels, they are considered to be part of edges. \n",
    "  #  Otherwise, they are also discarded\n",
    "  edges = cv2.Canny(threshold,50,150,apertureSize = 7)\n",
    "  contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  simplified_contours = []\n",
    "\n",
    "\n",
    "  for cnt in contours:\n",
    "      hull = cv2.convexHull(cnt)\n",
    "      simplified_contours.append(cv2.approxPolyDP(hull,\n",
    "                                0.001*cv2.arcLength(hull,True),True))\n",
    "  simplified_contours = np.array(simplified_contours)\n",
    "  biggest_n,approx_contour = biggest_contour(simplified_contours,image_size)\n",
    "\n",
    "  threshold = cv2.drawContours(image, simplified_contours ,biggest_n, (0,255,0), 1)\n",
    "\n",
    "  dst = 0\n",
    "  if approx_contour is not None and len(approx_contour)==4:\n",
    "      approx_contour=np.float32(approx_contour)\n",
    "      dst=four_point_transform(threshold,approx_contour)\n",
    "  croppedImage = dst\n",
    "  return croppedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10048\\3599270032.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  simplified_contours = np.array(simplified_contours)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformation(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
